[
  {
    "objectID": "ojs_quarto.html",
    "href": "ojs_quarto.html",
    "title": "Introduction to l1rotation",
    "section": "",
    "text": "Factor models seek to distill often high dimensional data into a set of underlying or latent factors that capture much of the original variation in the data.\nWe say the data, \\(X\\), follows a factor structure if:\n\\[\n\\begin{align}\n\\underset{(n \\times 1)}{X_{t}} &= \\underset{(n \\times r)}{\\Lambda^{*}_{\\vphantom{t}}} \\underset{(r \\times 1)}{F_t} + \\underset{(n \\times 1)}{e_{t}} \\forall t, \\qquad \\text{or more compactly,} \\qquad \\underset{(T \\times n)}{X} = \\underset{(T \\times r)}{F} \\underset{(r \\times n)}{\\Lambda^{*'}}  + \\underset{(T \\times n)}{e}\n\\end{align}\n\\]\nwhere there are\n\n\\(T\\) rows (observations),\n\\(n\\) columns (variables), and\n\\(r\\) factors. And we can refer to\n\\(\\lambda_{ik}\\) as the entry in \\(\\Lambda^{*T}\\) in the \\(i\\)th row and \\(k\\)th column\n\nThis \\(\\lambda_{ik}\\) shows how factor \\(k\\) is related to, or “loads onto,” variable \\(i\\).\nNote that \\(r\\) can be learned from the data (cite) so we can assume that \\(r\\) is known. Next, we’re interested in estimating a set of factors \\(F\\), that compress the data into fewer columns, and loadings \\(\\Lambda^*\\), that show how the factors are related to the original columns. However, there is no unique \\(F\\) and \\(\\Lambda^*\\) that satisfies the equation above. In fact, infinitely many will. This is referred to as rotational indeterminacy and it can pose issues in the interpretability of the loadings matrix.\n\n\nTo see the problem, let \\(H\\) be any nonsingular \\(r \\times r\\) matrix. We can define \\(\\Lambda^0 = \\Lambda^* (H^T)^{-1}\\) and \\(F^0 = FH\\). This tells us that\n\\[\n\\begin{align}\nX & = F^0 \\Lambda^{0'} \\\\\n& = FH (H^{-1'})^T \\Lambda^{*'}\\\\\n& = FH H^{-1} \\Lambda^{*'} \\\\\n& = F \\Lambda^{*'}\n\\end{align}\n\\]\nHence \\(X\\) can be explained identically well by any “rotation” \\(H\\) of the loadings and factors, and each rotation provides a different interpretation of how the factors and variables are related. So how can we find the correct interpretation?\n\n\n\nThe key idea in Freyaldenhoven (2025) is that assuming a sparsity pattern in the true loadings matrix \\(\\Lambda^*\\) solves the issue of rotational indeterminacy since the sparsity pattern is not invariant to rotations. Intuitively, any rotation (or linear combination) of a sparse loading vector will be less sparse.\n\nLinear combinations of sparse loading vectors are generally dense (mostly nonzero)\nTherefore, there exists a linear combination of the estimated loading vectors that IS sparse!\n\nAssuming a certain amount of sparsity is fairly reasonable, particularly when we’re interested in factors that are thought to affect only a subset of the original columns (i.e., local factors). Such factors are common in economic applications.\nGiven this, we can observe that the principal component estimator provides us estimates of the true loadings matrix\n\n\n\nNow, how do we find this sparse linear combination of loading vectors?\n\nTake PCA as starting point to obtain \\(\\Lambda^0\\)\nFind loadings \\(\\Lambda^*\\) equal to the rotation of \\(\\Lambda^0\\) that minimizes the number of non-zero elements (the \\(l_0\\) norm) in the loading vectors\n\nHowever, the \\(l_0\\) norm is often infeasible to optimize over in practice. To see this, each point in the figure below is a vector in which the length held fixed as we traverse the unit circle. The distance from the origin to each point shows the size of each norm, with the red points being the \\(l_0\\) norm, the blue dots the \\(l_1\\) norm and the grey dots the \\(l_2\\) norm.\n\n\n\nGeometric Intuition of Various Norms\n\n\nEven though the \\(l_0\\) norm directly computes the number of nonzero elements, the \\(l_1\\) norm is minimized at the same points as the \\(l_0\\) norm. But it has the added advantage of being much easier to optimize over, comparing the smooth descent of the blue dots toward the point (0, 1) from either side, to the discontinuity that occurs as the red points approach (0, 1).\nSo throughout, we’ll continue, swapping the \\(l_1\\) norm for the \\(l_0\\) for these optimization benefits.\n\n\n\nLet’s consider a dataset we can visualize fully: we’ll use the following simulated data that has three columns (\\(n = 3\\)) and read it in as X and suppose we know that there are two factors, \\(r = 2\\). Below only the first 6 rows are printed, but there are 224 rows total.\n\n\n          V1         V2         V3\n1  0.6624031 -0.1829747 -0.5026830\n2  0.3709347  1.2174531 -1.1426082\n3 -1.2000343 -1.2247438 -1.6778625\n4  0.5225106  0.9187241 -0.5469126\n5  0.4667395 -0.8284538 -0.5829659\n6 -0.2022476 -0.1169972  0.1865991\n\n\nLet the true loadings matrix, \\(\\Lambda^*\\) be a matrix with 2 columns and 3 rows. As we can see there is a sparsity pattern in the matrix with the first factor affecting only the first column and the second factor affecting the second and third columns of \\(X\\).\n\n\n  loadings_1 loadings_2\n1   1.024946  0.0000000\n2   0.000000  1.3517553\n3   0.000000  0.2765392\n\n\nNow, let’s look at the PCA estimator for \\(X\\) for the first two principal components, which are much more dense than the true loading vectors above - the zeroes are no longer present. But, the principal component estimate still provides a great starting point as they will generally be linear combinations of the true loading vectors.\n\n\n  loadings_1 loadings_2\n1 -0.9331464 -1.4110908\n2 -1.3219055  0.6307241\n3 -0.6179026  0.7816712\n\n\nUsing these PCA vectors as a starting point, let’s visualize all of the data. Below is an interactive visualization of\n\nthe data points in \\(X\\),\nthe subspace spanned by the principal components (the blue plane)\nthe principal component vectors (yellow)\nthe true loadings vectors (maroon)\n\n\nmath = require('https://cdnjs.cloudflare.com/ajax/libs/mathjs/1.5.2/math.min.js')\nd3 = require(\"d3@3\")\n//functionPlot = require(\"https://unpkg.com/function-plot@1/dist/function-plot.js\")\n\nTHREE = {\n  const THREE = window.THREE = await require(\"three@0.130.0/build/three.min.js\");\n  await require(\"three@0.130.0/examples/js/controls/OrbitControls.js\").catch(() =&gt; {});\n  return THREE;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrenderer.domElement\n\n\n\n\n\n\nviewof theta_value = Inputs.range(\n  [-3.13, 3.13], \n  {value: 1.57, step: .01, label: \"Vector 1 angle (theta):\"}\n)\n\nviewof theta_value2 = Inputs.range(\n  [-3.13, 3.13], \n  {value: 3.13, step: .01, label: \"Vector 2 angle (theta):\"}\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhighlighted_points = obj_data.filter(function(penguin) {\n  return (theta_value - 0.005 &lt; penguin.theta && theta_value + 0.005 &gt; penguin.theta) ||\n         (theta_value2 - 0.005 &lt; penguin.theta && theta_value2 + 0.005 &gt; penguin.theta)\n})\n\nobj_data = FileAttachment(\"data/obj_function_data.csv\").csv({typed: true});\n\nPlot.plot({\n  height: 100,\n  width: 700,\n  grid: true,\n  marks: [\n    Plot.dot(obj_data, {\n      x: \"theta\", \n      y: \"y\",\n      r: 1\n    }),\n    Plot.dot(highlighted_points, {\n      x: \"theta\", \n      y: \"y\", \n      fill: \"orange\", \n      r: 5\n    })\n  ],\n  y: {\n    label: \"\"\n  },\n  title: \"Objective function\",\n  style: {\n    background: \"transparent\",\n    fontSize: 12\n  }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nheight = 500;\ncamera = {\n  const fov = 45;\n  const aspect = width / height;\n  const near = 1;\n  const far = 1000;\n  const camera = new THREE.PerspectiveCamera(fov, aspect, near, far);\n  camera.position.set(2, 2, -2)\n  camera.lookAt(new THREE.Vector3(0, 0, 0));\n  return camera;\n}\naxesHelper = {const axesHelper = new THREE.AxesHelper( 5 );\nreturn axesHelper;\n}\n\ngridHelper = {const size = 10;\nconst divisions = 10;\n\nconst gridHelper = new THREE.GridHelper( size, divisions );\nreturn gridHelper;\n}\n\nrenderer = {\n  const renderer = new THREE.WebGLRenderer({antialias: true});\n  renderer.setSize(width, height);\n  renderer.setPixelRatio(devicePixelRatio);\n  const controls = new THREE.OrbitControls(camera, renderer.domElement);\n  controls.addEventListener(\"change\", () =&gt; renderer.render(scene, camera));\n  invalidation.then(() =&gt; (controls.dispose(), renderer.dispose()));\n  return renderer;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npca_vectors = await FileAttachment('data/lambda0.csv').csv({typed: true})\ntrue_vectors = await FileAttachment('data/truth_normal.csv').csv({typed: true})\n\n\ndisplay_arrow = {const dir = new THREE.Vector3( pca_vectors[0].V1, pca_vectors[1].V1, pca_vectors[2].V1);\n\n//normalize the direction vector (convert to vector of length 1)\ndir.normalize();\n\nconst origin = new THREE.Vector3( 0, 0, 0 );\nconst length = 1;\nconst hex = 0xFFA500;\n\nconst arrowHelper = new THREE.ArrowHelper( dir, origin, length, hex );\nreturn arrowHelper;\n        }\n        \ndisplay_arrow2 = {const dir = new THREE.Vector3( pca_vectors[0].V2, pca_vectors[1].V2, pca_vectors[2].V2);\n\n//normalize the direction vector (convert to vector of length 1)\ndir.normalize();\n\nconst origin = new THREE.Vector3( 0, 0, 0 );\nconst length = 1;\nconst hex = 0xFFA500;\n\nconst arrowHelper = new THREE.ArrowHelper( dir, origin, length, hex );\nreturn arrowHelper;\n        }\n        \n        \ntrue_vector1 = {const dir = new THREE.Vector3( true_vectors[0].V1, true_vectors[1].V1, true_vectors[2].V1);\n\n//normalize the direction vector (convert to vector of length 1)\ndir.normalize();\n\nconst origin = new THREE.Vector3( 0, 0, 0 );\nconst length = 1;\nconst hex = 0x0000FF;\n\nconst arrowHelper = new THREE.ArrowHelper( dir, origin, length, hex );\nreturn arrowHelper;\n        }\n        \ntrue_vector2 = {const dir = new THREE.Vector3( true_vectors[0].V2, true_vectors[1].V2, true_vectors[2].V2);\n\n//normalize the direction vector (convert to vector of length 1)\ndir.normalize();\n\nconst origin = new THREE.Vector3( 0, 0, 0 );\nconst length = 1;\nconst hex = 0x0000FF;\n\nconst arrowHelper = new THREE.ArrowHelper( dir, origin, length, hex );\nreturn arrowHelper;\n        }\n        \n        \n        \nmath_plane = {\n  const v1 = new THREE.Vector3( pca_vectors[0].V1, pca_vectors[1].V1, pca_vectors[2].V1 )\n  const v2 = new THREE.Vector3( pca_vectors[0].V2, pca_vectors[1].V2, pca_vectors[2].V2 )\n  const normal = new THREE.Vector3().crossVectors(v1, v2).normalize();\n  const plane = new THREE.Plane(normal);\n  const helper = new THREE.PlaneHelper( plane, 2, 0x0000FF );\n  return helper;\n  \n}       \n\n\n\npoints = {\n  const data = await FileAttachment('data/data.csv').csv({typed: true});\n  const geometry = new THREE.BufferGeometry();\n  const positions = new Float32Array(data.flatMap(d =&gt; [d.V1, d.V2, d.V3]));\n  geometry.setAttribute(\"position\", new THREE.BufferAttribute(positions, 3));\n\n  const material = new THREE.PointsMaterial({color: 0x000000, size: 0.1});\n  const points = new THREE.Points(geometry, material);\n  return points\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscene = {\n  const scene = new THREE.Scene();\n  scene.background = new THREE.Color(0xffffff);\n  scene.add(gridHelper);\n  scene.add(axesHelper);\n  scene.add(display_arrow);\n  scene.add(display_arrow2);\n  scene.add(true_vector1);\n  scene.add(true_vector2);\n  scene.add(math_plane);\n  scene.add(points);\n  return scene;\n}\n\n{const normal = math_plane.plane.normal;\nconst rotation_matrix = new THREE.Matrix4().makeRotationAxis(normal, theta_value);\nconst new_direction = new THREE.Vector3(pca_vectors[0].V1, pca_vectors[1].V1, pca_vectors[2].V1).normalize().applyMatrix4(rotation_matrix);\ndisplay_arrow.setDirection(new_direction);             \nrenderer.render(scene, camera);\nyield null;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{const normal = math_plane.plane.normal;\nconst rotation_matrix = new THREE.Matrix4().makeRotationAxis(normal, theta_value2);\nconst new_direction = new THREE.Vector3(pca_vectors[0].V2, pca_vectors[1].V2, pca_vectors[2].V2).normalize().applyMatrix4(rotation_matrix);\ndisplay_arrow2.setDirection(new_direction);             \nrenderer.render(scene, camera);\nyield null;\n\n}"
  },
  {
    "objectID": "ojs_quarto.html#background-and-intuition",
    "href": "ojs_quarto.html#background-and-intuition",
    "title": "Introduction to l1rotation",
    "section": "",
    "text": "Factor models seek to distill often high dimensional data into a set of underlying or latent factors that capture much of the original variation in the data.\nWe say the data, \\(X\\), follows a factor structure if:\n\\[\n\\begin{align}\n\\underset{(n \\times 1)}{X_{t}} &= \\underset{(n \\times r)}{\\Lambda^{*}_{\\vphantom{t}}} \\underset{(r \\times 1)}{F_t} + \\underset{(n \\times 1)}{e_{t}} \\forall t, \\qquad \\text{or more compactly,} \\qquad \\underset{(T \\times n)}{X} = \\underset{(T \\times r)}{F} \\underset{(r \\times n)}{\\Lambda^{*'}}  + \\underset{(T \\times n)}{e}\n\\end{align}\n\\]\nwhere there are\n\n\\(T\\) rows (observations),\n\\(n\\) columns (variables), and\n\\(r\\) factors. And we can refer to\n\\(\\lambda_{ik}\\) as the entry in \\(\\Lambda^{*T}\\) in the \\(i\\)th row and \\(k\\)th column\n\nThis \\(\\lambda_{ik}\\) shows how factor \\(k\\) is related to, or “loads onto,” variable \\(i\\).\nNote that \\(r\\) can be learned from the data (cite) so we can assume that \\(r\\) is known. Next, we’re interested in estimating a set of factors \\(F\\), that compress the data into fewer columns, and loadings \\(\\Lambda^*\\), that show how the factors are related to the original columns. However, there is no unique \\(F\\) and \\(\\Lambda^*\\) that satisfies the equation above. In fact, infinitely many will. This is referred to as rotational indeterminacy and it can pose issues in the interpretability of the loadings matrix.\n\n\nTo see the problem, let \\(H\\) be any nonsingular \\(r \\times r\\) matrix. We can define \\(\\Lambda^0 = \\Lambda^* (H^T)^{-1}\\) and \\(F^0 = FH\\). This tells us that\n\\[\n\\begin{align}\nX & = F^0 \\Lambda^{0'} \\\\\n& = FH (H^{-1'})^T \\Lambda^{*'}\\\\\n& = FH H^{-1} \\Lambda^{*'} \\\\\n& = F \\Lambda^{*'}\n\\end{align}\n\\]\nHence \\(X\\) can be explained identically well by any “rotation” \\(H\\) of the loadings and factors, and each rotation provides a different interpretation of how the factors and variables are related. So how can we find the correct interpretation?\n\n\n\nThe key idea in Freyaldenhoven (2025) is that assuming a sparsity pattern in the true loadings matrix \\(\\Lambda^*\\) solves the issue of rotational indeterminacy since the sparsity pattern is not invariant to rotations. Intuitively, any rotation (or linear combination) of a sparse loading vector will be less sparse.\n\nLinear combinations of sparse loading vectors are generally dense (mostly nonzero)\nTherefore, there exists a linear combination of the estimated loading vectors that IS sparse!\n\nAssuming a certain amount of sparsity is fairly reasonable, particularly when we’re interested in factors that are thought to affect only a subset of the original columns (i.e., local factors). Such factors are common in economic applications.\nGiven this, we can observe that the principal component estimator provides us estimates of the true loadings matrix\n\n\n\nNow, how do we find this sparse linear combination of loading vectors?\n\nTake PCA as starting point to obtain \\(\\Lambda^0\\)\nFind loadings \\(\\Lambda^*\\) equal to the rotation of \\(\\Lambda^0\\) that minimizes the number of non-zero elements (the \\(l_0\\) norm) in the loading vectors\n\nHowever, the \\(l_0\\) norm is often infeasible to optimize over in practice. To see this, each point in the figure below is a vector in which the length held fixed as we traverse the unit circle. The distance from the origin to each point shows the size of each norm, with the red points being the \\(l_0\\) norm, the blue dots the \\(l_1\\) norm and the grey dots the \\(l_2\\) norm.\n\n\n\nGeometric Intuition of Various Norms\n\n\nEven though the \\(l_0\\) norm directly computes the number of nonzero elements, the \\(l_1\\) norm is minimized at the same points as the \\(l_0\\) norm. But it has the added advantage of being much easier to optimize over, comparing the smooth descent of the blue dots toward the point (0, 1) from either side, to the discontinuity that occurs as the red points approach (0, 1).\nSo throughout, we’ll continue, swapping the \\(l_1\\) norm for the \\(l_0\\) for these optimization benefits.\n\n\n\nLet’s consider a dataset we can visualize fully: we’ll use the following simulated data that has three columns (\\(n = 3\\)) and read it in as X and suppose we know that there are two factors, \\(r = 2\\). Below only the first 6 rows are printed, but there are 224 rows total.\n\n\n          V1         V2         V3\n1  0.6624031 -0.1829747 -0.5026830\n2  0.3709347  1.2174531 -1.1426082\n3 -1.2000343 -1.2247438 -1.6778625\n4  0.5225106  0.9187241 -0.5469126\n5  0.4667395 -0.8284538 -0.5829659\n6 -0.2022476 -0.1169972  0.1865991\n\n\nLet the true loadings matrix, \\(\\Lambda^*\\) be a matrix with 2 columns and 3 rows. As we can see there is a sparsity pattern in the matrix with the first factor affecting only the first column and the second factor affecting the second and third columns of \\(X\\).\n\n\n  loadings_1 loadings_2\n1   1.024946  0.0000000\n2   0.000000  1.3517553\n3   0.000000  0.2765392\n\n\nNow, let’s look at the PCA estimator for \\(X\\) for the first two principal components, which are much more dense than the true loading vectors above - the zeroes are no longer present. But, the principal component estimate still provides a great starting point as they will generally be linear combinations of the true loading vectors.\n\n\n  loadings_1 loadings_2\n1 -0.9331464 -1.4110908\n2 -1.3219055  0.6307241\n3 -0.6179026  0.7816712\n\n\nUsing these PCA vectors as a starting point, let’s visualize all of the data. Below is an interactive visualization of\n\nthe data points in \\(X\\),\nthe subspace spanned by the principal components (the blue plane)\nthe principal component vectors (yellow)\nthe true loadings vectors (maroon)\n\n\nmath = require('https://cdnjs.cloudflare.com/ajax/libs/mathjs/1.5.2/math.min.js')\nd3 = require(\"d3@3\")\n//functionPlot = require(\"https://unpkg.com/function-plot@1/dist/function-plot.js\")\n\nTHREE = {\n  const THREE = window.THREE = await require(\"three@0.130.0/build/three.min.js\");\n  await require(\"three@0.130.0/examples/js/controls/OrbitControls.js\").catch(() =&gt; {});\n  return THREE;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrenderer.domElement\n\n\n\n\n\n\nviewof theta_value = Inputs.range(\n  [-3.13, 3.13], \n  {value: 1.57, step: .01, label: \"Vector 1 angle (theta):\"}\n)\n\nviewof theta_value2 = Inputs.range(\n  [-3.13, 3.13], \n  {value: 3.13, step: .01, label: \"Vector 2 angle (theta):\"}\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhighlighted_points = obj_data.filter(function(penguin) {\n  return (theta_value - 0.005 &lt; penguin.theta && theta_value + 0.005 &gt; penguin.theta) ||\n         (theta_value2 - 0.005 &lt; penguin.theta && theta_value2 + 0.005 &gt; penguin.theta)\n})\n\nobj_data = FileAttachment(\"data/obj_function_data.csv\").csv({typed: true});\n\nPlot.plot({\n  height: 100,\n  width: 700,\n  grid: true,\n  marks: [\n    Plot.dot(obj_data, {\n      x: \"theta\", \n      y: \"y\",\n      r: 1\n    }),\n    Plot.dot(highlighted_points, {\n      x: \"theta\", \n      y: \"y\", \n      fill: \"orange\", \n      r: 5\n    })\n  ],\n  y: {\n    label: \"\"\n  },\n  title: \"Objective function\",\n  style: {\n    background: \"transparent\",\n    fontSize: 12\n  }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nheight = 500;\ncamera = {\n  const fov = 45;\n  const aspect = width / height;\n  const near = 1;\n  const far = 1000;\n  const camera = new THREE.PerspectiveCamera(fov, aspect, near, far);\n  camera.position.set(2, 2, -2)\n  camera.lookAt(new THREE.Vector3(0, 0, 0));\n  return camera;\n}\naxesHelper = {const axesHelper = new THREE.AxesHelper( 5 );\nreturn axesHelper;\n}\n\ngridHelper = {const size = 10;\nconst divisions = 10;\n\nconst gridHelper = new THREE.GridHelper( size, divisions );\nreturn gridHelper;\n}\n\nrenderer = {\n  const renderer = new THREE.WebGLRenderer({antialias: true});\n  renderer.setSize(width, height);\n  renderer.setPixelRatio(devicePixelRatio);\n  const controls = new THREE.OrbitControls(camera, renderer.domElement);\n  controls.addEventListener(\"change\", () =&gt; renderer.render(scene, camera));\n  invalidation.then(() =&gt; (controls.dispose(), renderer.dispose()));\n  return renderer;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npca_vectors = await FileAttachment('data/lambda0.csv').csv({typed: true})\ntrue_vectors = await FileAttachment('data/truth_normal.csv').csv({typed: true})\n\n\ndisplay_arrow = {const dir = new THREE.Vector3( pca_vectors[0].V1, pca_vectors[1].V1, pca_vectors[2].V1);\n\n//normalize the direction vector (convert to vector of length 1)\ndir.normalize();\n\nconst origin = new THREE.Vector3( 0, 0, 0 );\nconst length = 1;\nconst hex = 0xFFA500;\n\nconst arrowHelper = new THREE.ArrowHelper( dir, origin, length, hex );\nreturn arrowHelper;\n        }\n        \ndisplay_arrow2 = {const dir = new THREE.Vector3( pca_vectors[0].V2, pca_vectors[1].V2, pca_vectors[2].V2);\n\n//normalize the direction vector (convert to vector of length 1)\ndir.normalize();\n\nconst origin = new THREE.Vector3( 0, 0, 0 );\nconst length = 1;\nconst hex = 0xFFA500;\n\nconst arrowHelper = new THREE.ArrowHelper( dir, origin, length, hex );\nreturn arrowHelper;\n        }\n        \n        \ntrue_vector1 = {const dir = new THREE.Vector3( true_vectors[0].V1, true_vectors[1].V1, true_vectors[2].V1);\n\n//normalize the direction vector (convert to vector of length 1)\ndir.normalize();\n\nconst origin = new THREE.Vector3( 0, 0, 0 );\nconst length = 1;\nconst hex = 0x0000FF;\n\nconst arrowHelper = new THREE.ArrowHelper( dir, origin, length, hex );\nreturn arrowHelper;\n        }\n        \ntrue_vector2 = {const dir = new THREE.Vector3( true_vectors[0].V2, true_vectors[1].V2, true_vectors[2].V2);\n\n//normalize the direction vector (convert to vector of length 1)\ndir.normalize();\n\nconst origin = new THREE.Vector3( 0, 0, 0 );\nconst length = 1;\nconst hex = 0x0000FF;\n\nconst arrowHelper = new THREE.ArrowHelper( dir, origin, length, hex );\nreturn arrowHelper;\n        }\n        \n        \n        \nmath_plane = {\n  const v1 = new THREE.Vector3( pca_vectors[0].V1, pca_vectors[1].V1, pca_vectors[2].V1 )\n  const v2 = new THREE.Vector3( pca_vectors[0].V2, pca_vectors[1].V2, pca_vectors[2].V2 )\n  const normal = new THREE.Vector3().crossVectors(v1, v2).normalize();\n  const plane = new THREE.Plane(normal);\n  const helper = new THREE.PlaneHelper( plane, 2, 0x0000FF );\n  return helper;\n  \n}       \n\n\n\npoints = {\n  const data = await FileAttachment('data/data.csv').csv({typed: true});\n  const geometry = new THREE.BufferGeometry();\n  const positions = new Float32Array(data.flatMap(d =&gt; [d.V1, d.V2, d.V3]));\n  geometry.setAttribute(\"position\", new THREE.BufferAttribute(positions, 3));\n\n  const material = new THREE.PointsMaterial({color: 0x000000, size: 0.1});\n  const points = new THREE.Points(geometry, material);\n  return points\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscene = {\n  const scene = new THREE.Scene();\n  scene.background = new THREE.Color(0xffffff);\n  scene.add(gridHelper);\n  scene.add(axesHelper);\n  scene.add(display_arrow);\n  scene.add(display_arrow2);\n  scene.add(true_vector1);\n  scene.add(true_vector2);\n  scene.add(math_plane);\n  scene.add(points);\n  return scene;\n}\n\n{const normal = math_plane.plane.normal;\nconst rotation_matrix = new THREE.Matrix4().makeRotationAxis(normal, theta_value);\nconst new_direction = new THREE.Vector3(pca_vectors[0].V1, pca_vectors[1].V1, pca_vectors[2].V1).normalize().applyMatrix4(rotation_matrix);\ndisplay_arrow.setDirection(new_direction);             \nrenderer.render(scene, camera);\nyield null;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{const normal = math_plane.plane.normal;\nconst rotation_matrix = new THREE.Matrix4().makeRotationAxis(normal, theta_value2);\nconst new_direction = new THREE.Vector3(pca_vectors[0].V2, pca_vectors[1].V2, pca_vectors[2].V2).normalize().applyMatrix4(rotation_matrix);\ndisplay_arrow2.setDirection(new_direction);             \nrenderer.render(scene, camera);\nyield null;\n\n}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "quarto-example",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]